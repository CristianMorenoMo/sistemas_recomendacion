{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "premium-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import KNNBasic\n",
    "from surprise import accuracy\n",
    "from random import sample\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%reload_ext sql\n",
    "%sql postgresql://studentrs:szcWuiyxVnKO38XfzHkP@workshop1rs.cevhjouwoh1r.us-east-2.rds.amazonaws.com/workshop_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "egyptian-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  seleccionar items distribucion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electoral-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class recommender_model():\n",
    "    '''\n",
    "    df = query txt users\n",
    "    rating_matrix =  \n",
    "    '''\n",
    "    def __init__(self,df):\n",
    "        self.data_sample = df\n",
    "        \n",
    "    def rating_matrix(self):\n",
    "        aux_artistas = self.data_sample.groupby('UserId').agg({'ArtId':'nunique'}).reset_index().rename(columns = {'ArtId':'Nart'})\n",
    "        ratings_artistas = self.data_sample.groupby(['UserId', 'ArtId']).size().reset_index(name = 'frecuencia')\n",
    "        ratings_artistas_merged = ratings_artistas.merge(aux_artistas, on = 'UserId', how = 'left')\n",
    "        ratings_artistas_merged['normalizada'] = ratings_artistas_merged['frecuencia']/ratings_artistas_merged['Nart']\n",
    "        ratings_artistas_merged = ratings_artistas_merged.drop('Nart', axis = 1)\n",
    "        self.ratings_artistas = ratings_artistas_merged\n",
    "        \n",
    "    def K_neigbors(self):\n",
    "        reader = Reader(rating_scale = (min(self.ratings_artistas['normalizada']),\n",
    "                                        max(self.ratings_artistas['normalizada']) ))\n",
    "        surprise_dataset = Dataset.load_from_df(self.ratings_artistas[['UserId','ArtId','normalizada']],\n",
    "                                                reader)\n",
    "        train_set, test_set = train_test_split(surprise_dataset, test_size=.2)\n",
    "        k,value = [],[]\n",
    "        for i in range(50,80,5):\n",
    "            sim_options = {'name': 'cosine',\n",
    "                           'user_based': False}\n",
    "\n",
    "            algo = KNNBasic(k = i, min_k = 2, sim_options = sim_options)\n",
    "            algo.fit(trainset = train_set)\n",
    "            test_predictions = algo.test(test_set)\n",
    "            value.append(accuracy.rmse(test_predictions, verbose = True))\n",
    "            k.append(i)\n",
    "        n = [i for i in range(len(value)) if value[i] == min(value)]\n",
    "        self.k = k[n[0]]\n",
    "        self.surprise_dataset = surprise_dataset\n",
    "    def Knn_filtering (self):\n",
    "        rating_data = self.surprise_dataset.build_full_trainset()\n",
    "        test = rating_data.build_anti_testset()\n",
    "        joblib.dump(test,'modelo_entrenado/user_predict.joblib')\n",
    "        sim_options = {'name': 'cosine',\n",
    "                       'user_based': False} \n",
    "        algo = KNNBasic(k = self.k, min_k = 2, sim_options = sim_options)\n",
    "        algo.fit(rating_data)\n",
    "        filename = 'modelo_entrenado/recomender_model_colaborative.sav'\n",
    "        joblib.dump(algo, filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "analyzed-bouquet",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://studentrs:***@workshop1rs.cevhjouwoh1r.us-east-2.rds.amazonaws.com/workshop_1\n",
      "15669919 rows affected.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0257\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0251\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0252\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0252\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0252\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0251\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Wall time: 32min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = %sql select user_id as UserId, artist_id as ArtId from items_requestedplay;\n",
    "df = query.DataFrame()\n",
    "df = df.rename(columns = {'userid':'UserId', 'artid':'ArtId'})\n",
    "model = recommender_model(df)\n",
    "model.rating_matrix()\n",
    "model.K_neigbors()\n",
    "model.Knn_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metric-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_artistas = df.groupby('UserId').agg({'ArtId':'nunique'}).reset_index().rename(columns = {'ArtId':'Nart'})\n",
    "ratings_artistas = df.groupby(['UserId', 'ArtId']).size().reset_index(name = 'frecuencia')\n",
    "ratings_artistas_merged = ratings_artistas.merge(aux_artistas, on = 'UserId', how = 'left')\n",
    "ratings_artistas_merged['normalizada'] = ratings_artistas_merged['frecuencia']/ratings_artistas_merged['Nart']\n",
    "ratings_artistas_merged = ratings_artistas_merged.drop('Nart', axis = 1)\n",
    "ratings_artistas = ratings_artistas_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "working-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale = (min(ratings_artistas['normalizada']),\n",
    "                                        max(ratings_artistas['normalizada']) ))\n",
    "surprise_dataset = Dataset.load_from_df(ratings_artistas[['UserId','ArtId','normalizada']],\n",
    "                                                reader)\n",
    "train_set, test_set = train_test_split(surprise_dataset, test_size=.2)\n",
    "k,value = [],[]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
